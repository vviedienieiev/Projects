{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Language of text",
      "provenance": [],
      "authorship_tag": "ABX9TyOcO1G+6n+9VStFAYmPxVPZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vviedienieiev/Projects/blob/master/Ukrainian_language_share/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrvGDAXiaeQ5"
      },
      "source": [
        "!pip install polyglot  \n",
        "!pip install pyicu     \n",
        "!pip install Morfessor   \n",
        "!pip install pycld2 \n",
        "!pip install langdetect"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7y4tLXnyaJSH"
      },
      "source": [
        "from polyglot.detect import Detector\n",
        "from polyglot.detect.base import logger\n",
        "logger.disabled = True\n",
        "from langdetect import detect\n",
        "import numpy as np\n",
        "import string\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nh0IPUl9aXaD"
      },
      "source": [
        "data = np.load(\"all_message.npy\",allow_pickle=True) #get the data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gl-tlvyeb0gp"
      },
      "source": [
        "exclude_punctuation = set(string.punctuation) #list of all punctuation symbols\n",
        "exclude_numbers = string.digits #list of all digits\n",
        "exclude_english = string.ascii_letters #list of all english upper and lower case letters\n",
        "exclude_other = ['‚Äî','ÃÅ','¬´', '¬ª','üåö', 'ü§î','‚Ä¶', 'üòÜ','ü§°','‚Äì', 'ü§ó','\\u200b', 'üòÖ', 'üôè', 'üèª', 'üòò', 'ü•∫', 'üòå',\n",
        "                 'üò¨','üò¢', 'ü§¶', '‚ôÇ', 'Ô∏è', 'üëç', 'üòè', 'üò®', 'üòÇ', 'üòÉ', 'üòê',\n",
        "                 'ü§∑','‚ôÄ', 'üî∫', 'üò≠', 'üòÅ', '‚óæ', 'üôà', 'ü•≥', '¬±', 'üë¥', 'üòà', 'üò∂', '\\u200d'] # list of other symbols"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExRZXrFVcAH4"
      },
      "source": [
        "final_set = [text for text in data if text is not None] #remove empty elements\n",
        "final_set = \" \".join(final_set) #convert to string\n",
        "final_set = ''.join(ch for ch in final_set if ch not in exclude_punctuation) #remove punctuation\n",
        "final_set = ''.join(ch for ch in final_set if ch not in exclude_numbers) # remove numbers\n",
        "final_set = ''.join(ch for ch in final_set if ch not in exclude_english) # remove english characters\n",
        "final_set = ''.join(ch for ch in final_set if ch not in exclude_other) # remove other symbols\n",
        "final_set = final_set.split(\" \") # make tokenezation\n",
        "final_set = [word for word in final_set if len(word) > 2] # remove all small words\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Au856Z_TcreZ",
        "outputId": "9651736e-9b16-4362-818b-b191d63dd3b9"
      },
      "source": [
        "##### MODEL 1 #####\n",
        "languages = [Detector(word, quiet=True).language.name for word in final_set] # detect language of the word\n",
        "Counter(languages) # count amount of words within each language\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'Abkhazian': 1109,\n",
              "         'Bashkir': 701,\n",
              "         'Belarusian': 12838,\n",
              "         'Bulgarian': 12048,\n",
              "         'Kazakh': 1720,\n",
              "         'Kyrgyz': 2673,\n",
              "         'Macedonian': 5911,\n",
              "         'Mongolian': 1259,\n",
              "         'Romanian': 2724,\n",
              "         'Russian': 164682,\n",
              "         'Serbian': 29297,\n",
              "         'Tajik': 2721,\n",
              "         'Tatar': 1287,\n",
              "         'Turkmen': 1304,\n",
              "         'Ukrainian': 272056,\n",
              "         'Uyghur': 1240,\n",
              "         'Uzbek': 2775,\n",
              "         'un': 13972})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVd34XqcZsrv",
        "outputId": "4ba45beb-011b-44cb-e619-1e452b44bfdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Model 2\n",
        "detectors = [Detector(word, quiet=True) for word in final_set]\n",
        "languages = [detector.language.name if detector.reliable else 'not_detected' for detector in detectors]\n",
        "Counter(languages)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'Abkhazian': 100,\n",
              "         'Belarusian': 2449,\n",
              "         'Bulgarian': 310,\n",
              "         'Kyrgyz': 82,\n",
              "         'Macedonian': 344,\n",
              "         'Romanian': 300,\n",
              "         'Russian': 16667,\n",
              "         'Serbian': 900,\n",
              "         'Tajik': 200,\n",
              "         'Ukrainian': 83115,\n",
              "         'Uyghur': 202,\n",
              "         'Uzbek': 200,\n",
              "         'not_detected': 425448})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87QtTJqiekl7",
        "outputId": "32707340-0445-48fc-a822-5542aef522e4"
      },
      "source": [
        "##### MODEL 3 #####\n",
        "#Ru share\n",
        "def get_ru_words():\n",
        "  url = \"http://slovardalja.net/\"\n",
        "  response = requests.get(url)\n",
        "  response.encoding = 'cp1251'\n",
        "  soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "  links = soup.select(\".chara\")\n",
        "  chars = [link.text.lower() for link in links]\n",
        "  links = [\"http://slovardalja.net/\"+link[\"href\"] for link in links]\n",
        "  all_words = []\n",
        "  for link in links:\n",
        "      response = requests.get(link)\n",
        "      response.encoding = 'cp1251'\n",
        "      soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "      words = soup.select(\".chara strong\")\n",
        "      all_words.extend(words)\n",
        "  all_words = [word.text.lower() for word in all_words if word.text.lower() not in chars]\n",
        "  all_words_str = \"\".join(all_words)\n",
        "  all_words_final = \"\".join(ch for ch in all_words_str if ch in chars)\n",
        "  return all_words_final\n",
        "\n",
        "#UA Share  \n",
        "def get_ua_words():\n",
        "  url = \"http://ukrlit.org/slovnyk/slovnyk_ukrainskoi_movy_v_11_tomakh\"\n",
        "  response = requests.get(url)\n",
        "  soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "  chars = soup.select(\".letter p\")\n",
        "  chars = [char.text for char in chars]\n",
        "  links = soup.select(\".letters__dropdown_opacity a\")\n",
        "  links = [\"http://ukrlit.org\"+link[\"href\"] for link in links]\n",
        "  all_words = []\n",
        "  for link in links:\n",
        "      response = requests.get(link)\n",
        "      soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "      words = soup.select(\".word-list__item a\")\n",
        "      words = [word.text.lower() for word in words]\n",
        "      all_words.extend(words)\n",
        "  all_words_str = \"\".join(all_words)\n",
        "  all_words_final = \"\".join(ch for ch in all_words_str if ch in chars)\n",
        "  return all_words_final\n",
        "\n",
        "\n",
        "#Calculate special chars in initial dataset\n",
        "final_set_model_2 = \" \".join(final_set)\n",
        "ukr = final_set_model_2.count(\"—ñ\")+final_set_model_2.count(\"—î\")+final_set_model_2.count(\"—ó\")\n",
        "rus = final_set_model_2.count(\"—ã\")+final_set_model_2.count(\"—ä\")+final_set_model_2.count(\"—ç\")\n",
        "\n",
        "all_words_ru = get_ru_words()\n",
        "share_ru = (all_words_ru.count(\"—ã\")+all_words_ru.count(\"—ä\")+all_words_ru.count(\"—ç\"))/len(all_words_ru)\n",
        "\n",
        "all_words_ua = get_ua_words()\n",
        "share_ua = (all_words_ua.count(\"—ñ\")+all_words_ua.count(\"—î\")+all_words_ua.count(\"—ó\"))/len(all_words_ua)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "175089 11251 0.06037887732102608\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrXrSaF9qqlA",
        "outputId": "1bd34e91-2fb9-45bb-ef50-de412d8c1291",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(f\"Amount of ukrainian chars in dataset {ukr}\")\n",
        "print(f\"Amount of russian chars in dataset {rus}\")\n",
        "print(f\"Share of russian chars in dataset {rus/(rus+ukr)}\")\n",
        "print(f\"Frequence of ukrainian chars among ukrainian words {share_ua*100}%\")\n",
        "print(f\"Frequence of russian chars among ukrainian words {share_ru*100}%\")\n",
        "print(f\"Adjusted amount of russian words {rus/(rus+ukr)*(share_ua/share_ru)*100}%\")\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Amount of ukrainian chars in dataset 175089\n",
            "Amount of russian chars in dataset 11251\n",
            "Share of russian chars in dataset 0.06037887732102608\n",
            "Frequence of ukrainian chars among ukrainian words 4.505183548063595%\n",
            "Frequence of russian chars among ukrainian words 2.264657623863714%\n",
            "Adjusted amount of russian words 12%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}